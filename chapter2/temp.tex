\section{用tf.estimator创建Estimator}
tf.estimator框架使得通过他的高级Estimator API构造和训练机器学习模型变得很容易。Estimator提供你能快速配置昌建模型类型的想regressors和classfiers类快速实例化。
\begin{itemize}
	\item \href{https://www.tensorflow.org/api_docs/python/tf/estimator/LinearClassifier}{tf.estimator.LinearClassifier}构造一个现行分类器模型
	\item \href{https://www.tensorflow.org/api_docs/python/tf/estimator/LinearRegressor}{tf.estimator.LinearRegressor}构造一个线性回归模型
	\item \href{https://www.tensorflow.org/api_docs/python/tf/estimator/DNNClassifier}{tf.estimator.DNNClassifier}构造一个神经网络分类器
	\item \href{https://www.tensorflow.org/api_docs/python/tf/estimator/DNNRegressor}{tf.estimator.DNNRegressor}构造一个神经网络和现行结合的分类模型
	\item \href{https://www.tensorflow.org/api_docs/python/tf/estimator/DNNLinearCombinedClassifier}{tf.estimator.DNNLinearCombinedClassifier}构造一个神经网络和线性结合的回归模型
	\item \href{https://www.tensorflow.org/api_docs/python/tf/estimator/DNNLinearCombinedRegressor}{tf.estimator.DNNLinearCombinedRegressor}
\end{itemize}
但是如果tf.estimator中没有一个预定义的模型满足你的需要怎么办?也许你需要在模型配置上进行更加精细的配置，像为优化器自定义损失函数，或者为不同的神经层指定不同的激活函数。或者也许你正在实现一个排序或者推荐系统或者生成的预测既不分类也不回归。

这个导航包含如何通过使用tf.estimator提供的构建模块创建自己的Estimator，基于他们的物理度量预测\href{https://en.wikipedia.org/wiki/Abalone}{abalones}年龄。你将学习:
\begin{itemize}
	\item 实例化一个Estimator
	\item 构造一个自定义的模型函数
	\item 用tf.feature\_column和tf.layers配置神经网络
	\item 从tf.losses选择一个合适的损失函数
	\item 为你的模型定义一个训练操作
	\item 生成和返回预测
\end{itemize}
\subsection{预先要求}
这个导航需要你知道基础的tf.estimator API,像feature columns，输入函数和train(),evaluate(),predict()操作。如果你之前没有过tf.estimator,你应该首先查看下面的导航。
\begin{itemize}
	\item \href{https://www.tensorflow.org/get_started/estimator}{tf.estimator Quickstart}用tf.estimator训练神经网络的快速介绍
	\item \href{https://www.tensorflow.org/tutorials/wide}{TensorFlow Linear Model Tutorial}介绍feature columns,和用tf.estimator构建一个线性分类器概述
	\item \href{https://www.tensorflow.org/get_started/input_fn}{Building Input Functions with tf.estimator}如何构造一个input\_fn处理和输入数据到你的模型的概览
\end{itemize}
\subsection{一个Abalone年龄预测器}
通过壳上的环估计\href{https://en.wikipedia.org/wiki/Abalone}{abalon}(sea snail)的年龄是可能的，然而，在显微镜下查看壳，这个任务要求严被污染，希望能找到另一个测量方法预测年纪。

\href{https://archive.ics.uci.edu/ml/datasets/Abalone}{Abalone Data Set} 包含关于abalone的下面\href{https://archive.ics.uci.edu/ml/machine-learning-databases/abalone/abalone.names}{特征数据}
\begin{table}[!h]
	\begin{tabular}{|c|c|}
特征&描述\\
长度&abalone的长度（最长的方向，单位mm）\\
直径&abalone的周长(垂直方向上的长度单位mm)\\
高度&abalone的高度(肉在壳中，单位mm)\\
整体重量&abaline的整体重量(单位g)\\
去壳后的重量&肉的重量(单位g)\\
内脏重量&流血后的重量(单位g)\\
壳重量&abalone壳的重量(单位g)\\
\end{tabular}
\end{table}
标签预测环数作为abalone的年龄。
\begin{figure}[H]
	\centering
	%\includegrapgics[scale=0.5]{abalone_shell.jpg}
	\caption{Abalone shell (by Nicki Dugan Pogue, CC BY-SA 2.0)}
\end{figure}
\subsection{开始}
这个导航用三个数据集,\href{http://download.tensorflow.org/data/abalone_train.csv}{abalone\_train.csv}包含训练数据3320样本。\href{http://download.tensorflow.org/data/abalone_test.csv}{abalone\_test.csv}包含标记测试数据850个样本。\href{http://download.tensorflow.org/data/abalone_predict.csv}{abalone\_predict}包含7个预测样本。
下面的章节一步步写Estimator代码，完整的代码在\href{https://www.github.com/tensorflow/tensorflow/blob/r1.4/tensorflow/examples/tutorials/estimators/abalone.py}{这里}
\subsection{载入abalone csv数据到TensorFlow数据集}
为了输入数据进model,你讲需要下载cvs文件载入到TensorFlow Dataset。首先添加一些标准的Python和TensorFlow导入，设置FLAGS:
\begin{lstlisting}[language=Python]
from __future__ import absolute_import
from __future__ import division
from __future__ import print_function

import argparse
import sys
import tempfile

# Import urllib
from six.moves import urllib

import numpy as np
import tensorflow as tf

FLAGS = None
\end{lstlisting}
开启采集\lstinline[language=Python]{tf.logging.set_verbosity(tf.logging.INFO)}

然后定义一个函数载入CSV文件:
\begin{lstlisting}[language=Python]
def maybe_download(train_data, test_data, predict_data):
  ""Maybe downloads training data and returns train and test file names.""
  if train_data:
    train_file_name = train_data
  else:
    train_file = tempfile.NamedTemporaryFile(delete=False)
    urllib.request.urlretrieve(
        "http://download.tensorflow.org/data/abalone_train.csv",
        train_file.name)
    train_file_name = train_file.name
    train_file.close()
    print("Training data is downloaded to %s" % train_file_name)

  if test_data:
    test_file_name = test_data
  else:
    test_file = tempfile.NamedTemporaryFile(delete=False)
    urllib.request.urlretrieve(
        "http://download.tensorflow.org/data/abalone_test.csv", test_file.name)
    test_file_name = test_file.name
    test_file.close()
    print("Test data is downloaded to %s" % test_file_name)

  if predict_data:
    predict_file_name = predict_data
  else:
    predict_file = tempfile.NamedTemporaryFile(delete=False)
    urllib.request.urlretrieve(
        "http://download.tensorflow.org/data/abalone_predict.csv",
        predict_file.name)
    predict_file_name = predict_file.name
    predict_file.close()
    print("Prediction data is downloaded to %s" % predict_file_name)

  return train_file_name, test_file_name, predict_file_name"
\end{lstlisting}
最后创建main()载入csv文件进入Datasets，定义flags允许用户通过命令行选择制定CSV文件训练，测试和预测数据集

\begin{lstlisting}[language=Python]
def main(unused_argv):
  # Load datasets
  abalone_train, abalone_test, abalone_predict = maybe_download(
    FLAGS.train_data, FLAGS.test_data, FLAGS.predict_data)

  # Training examples
  training_set = tf.contrib.learn.datasets.base.load_csv_without_header(
      filename=abalone_train, target_dtype=np.int, features_dtype=np.float64)

  # Test examples
  test_set = tf.contrib.learn.datasets.base.load_csv_without_header(
      filename=abalone_test, target_dtype=np.int, features_dtype=np.float64)

  # Set of 7 examples for which to predict abalone ages
  prediction_set = tf.contrib.learn.datasets.base.load_csv_without_header(
      filename=abalone_predict, target_dtype=np.int, features_dtype=np.float64)

if __name__ == "__main__":
  parser = argparse.ArgumentParser()
  parser.register("type", "bool", lambda v: v.lower() == "true")
  parser.add_argument(
      "--train_data", type=str, default="", help="Path to the training data.")
  parser.add_argument(
      "--test_data", type=str, default="", help="Path to the test data.")
  parser.add_argument(
      "--predict_data",
      type=str,
      default="",
      help="Path to the prediction data.")
  FLAGS, unparsed = parser.parse_known_args()
  tf.app.run(main=main, argv=[sys.argv[0]] + unparsed)
\end{lstlisting}
\subsection{实例化一个Estimator}
当使用一个tf.estimator提供的类定义一个模型（想DNNClassifier）的时候，你在结构体中应用正确的配置参数。
\begin{lstlisting}[language=Python]
my_nn = tf.estimator.DNNClassifier(feature_columns=[age, height, weight],
                                   hidden_units=[10, 10, 10],
                                   activation_fn=tf.nn.relu,
                                   dropout=0.2,
                                   n_classes=3,
                                   optimizer="Adam")
\end{lstlisting}
你不需要写任何代码说明TensorFlow如何训练模型，计算损失，返回预测；这些逻辑已经写入的DNNClassifier。

通过对比，当你创建你自己的estimator的时候，构造体接受两个高级参数用于模型的配置，model\_fn和parms：
\lstinline[language=Python]{nn = tf.estimator.Estimator(model_fn=model_fn, params=model_params)}
\begin{itemize}
\item model\_fn:一个包含所有的上面提到的逻辑的函数对象支持训练，估计和预测。你只管实现功能，下一章节\href{https://www.tensorflow.org/extend/estimators#constructing-modelfn}{ Constructing the model\_fn}构造包含创建一个模型函数的细节。
\item params:一个可选的词典超参数(学习率，dropout)等将被传输进model\_fn。
\end{itemize}
\begin{quote}
\textbf{注意:}\emph{像tf.estimator的预先定义的回归和分类器一样，Estimator初始化器也接受通常的配置参数model\_dir和config}
\end{quote}
对于abalone预测器，模型将接受一个草参数:学习率。在你的代码的开头定义LEARNING\_RATE作为，之后配置采集:
\begin{lstlisting}[language=Python]
tf.logging.set_verbosity(tf.logging.INFO)

# Learning rate for the model
LEARNING_RATE = 0.001
\end{lstlisting}
\begin{quote}
\textbf{注意:}\emph{这里的LEARING\_RATE设置为0.001，但是当你需要更好的结果时你可以在训练过程中改变这个值}
\end{quote}
然后，添加下面代码到main(),创建字典model\_params包含学习率和实例化的Estimator:
\begin{lstlisting}[language=Python]
# Set model params
model_params = {"learning_rate": LEARNING_RATE}

# Instantiate Estimator
nn = tf.estimator.Estimator(model_fn=model_fn, params=model_params)
\end{lstlisting}
\subsection{构造model\_fn}
Estimator API的基本的框架像这样:
\begin{lstlisting}[language=Python]
def model_fn(features, labels, mode, params):
   # Logic to do the following:
   # 1. Configure the model via TensorFlow operations
   # 2. Define the loss function for training/evaluation
   # 3. Define the training operation/optimizer
   # 4. Generate predictions
   # 5. Return predictions/loss/train_op/eval_metric_ops in EstimatorSpec object
   return EstimatorSpec(mode, predictions, loss, train_op, eval_metric_ops)
\end{lstlisting}
model\_fn必须接受三个参数:
\begin{itemize}
	\item features：一个包含通过input\_fn传递待模型的包含特征的字典
	\item labels:一个Tensor包含通过input\_fn传递到模型的标签。当model自己推理的时候将出现空的调用
	\item mode:一个\href{https://www.tensorflow.org/api_docs/python/tf/estimator/ModeKeys}{tf.estimator.ModeKeys}字符串值指明model\_fn被调用的上下文:
		\begin{itemize}
	\item tf.estimator.ModeKeys.TRAIN model\_fn调用在训练模式下，也就是通过train()调用
	\item tf.estimator.ModeKeys.EVAL model\_fn在估计模式下调用，也就是通过evaluate调用
	\item tf.estimator.ModeKeys.PREDICT model\_fn在预测模式下调用，也就是通过predict()调用
		\end{itemize}
\end{itemize}
model\_fn也接受一个包含用于训练的草参数参数（正如上面框架介绍的）

函数执行的主题跟着下面的任务(更多的细节查看下面的章节)
\begin{itemize}
		\item 配置模型，对于abalone预测器，浙江是一个神经网络
		\item 定义用于计算预测结果和目标值接近程度的损失函数。
		\item 定义一个训练操作制定优化算法最小化损失值的计算
\end{itemize}
model\_fn必须返货一个\href{https://www.tensorflow.org/api_docs/python/tf/estimator/EstimatorSpecC}{tf.estimator.EstimatorSpec}对象，包含下面的值:
\begin{itemize}
	\item mode(要求)。模型运行的模式，通常你将返回model\_fn的mode参数
	\item predictions(要求在PREDICT模式下)。一个字典映射你的选择的名字为包含模型预测的Tensor。例如
		%\lstinline[language=Bash]{python predictions = {"results": tensor_of_predictions}}，在PREDICT模式，你在EstimatorSpec返回的字典将通过predict()返回，因此你可以用你想使用的方式构造它
	\item loss(要求EVAL和TRAIN模式)。一个包含有损失标量值的Tensor:模型损失函数(更深的讨论在\href{https://www.tensorflow.org/extend/estimators#defining_loss}{ Defining loss for the model})在输入计算后的的输出。这用于TRAIN模式用于处理错误和采集，自动作为度量包含在EVAL模式。
	\item train\_op:(仅仅要求在TRAIN模式)。一个返回训练步数的操作
	\item eval\_metric\_ops（可选）。一个name/value对制定当模型在EVAL模式下运行时制定将被计算的度量。你的选择的标签的名字用于度量，和你的度量计算的结果。\href{https://www.tensorflow.org/api_docs/python/tf/metrics}{tf.metrics}模块提供预定义的函数用于多种常规测量。
		下面的eval\_netric\_ops包含一个用tf.metrics.accuracy计算的accuracy方法:
		\begin{lstlisting}[language=Bash]{
			python eval_metric_ops = { "accuracy": tf.metrics.accuracy(labels, predictions) }}
		\end{lstlisting}
\end{itemize}
如果你没有指定evalue\_metric\_ops,仅仅loss将在估计的时候被计算。
\subsection{结合tf.feature\_column和tf.layers配置神经网络}
构造一个\href{https://en.wikipedia.org/wiki/Artificial_neural_network}{神经网络}需要创建和连接输入层，隐藏层和输出层。

输入层是一系列的节点(在模型中的一个特征)，节点通过在features参数接受特征输入传入model\_fn。如果features包含一个包含你的特征数据的n维Tensor，然后他可能为输入层服务。如果features包含一个\href{https://www.tensorflow.org/tutorials/linear#feature_columns_and_transformations}{feature columns }通过输入函数人传递给模型，你可以结合\href{https://www.tensorflow.org/api_docs/python/tf/feature_column/input_layer}{tf.feature\_column.input\_layer}函数转化输入层Tensor。
\begin{lstlisting}[language=Python]
input_layer = tf.feature_column.input_layer(
    features=features, feature_columns=[age, height, weight])
\end{lstlisting}
正如上面显示的,input\_layer()接受两个参数:
\begin{itemize}
		\item features:一个从字符串到包含对应feature数据的Tensor映射，它在model\_fn中的features参数被明确的传递
		\item feature\_columns：一个模型中所有的FeatureColumns的列表（年龄，高度，重量（上面例子））
\end{itemize}
神经网络的输入层必须通过一个\href{https://en.wikipedia.org/wiki/Activation_function}{activation function}连接到一个或者更多的隐藏层对前面层的数据执行非线性变换。最后的隐藏层然后连接最后一层的输出层。tf.layers提供tf.layers.dense函数构造全连接层。激活函数通过activation参数控制，一些选项传递给activation参数:
\begin{itemize}
	\item tf.nn.relu 下面的代码通过\href{https://en.wikipedia.org/wiki/Rectifier_(neural_networks)}{ReLU activation function}(\href{https://www.tensorflow.org/api_docs/python/tf/nn/relu}{tf.nn.relu})创建一个全连接到前一层input\_layer的层
	\item tf.nn.relu 后面的代码通过ReLU6激活函数创建一个和hidden\_layer的全连接层全连接单元层(\href{https://www.tensorflow.org/api_docs/python/tf/nn/relu6}{tf.nn.relu})
	\item None下面的代码没有激活函数创建一个和前一层second\_hidden\_layer全连接的单元层，仅仅是一个线性变换
		\begin{lstlisting}[language=Bash]
		python output_layer = tf.layers.dense( inputs=second_hidden_layer, units=3, activation=None)
		\end{lstlisting}
\end{itemize}
其他可能的激活函数，例如
\begin{lstlisting}[language=Python]
output_layer = tf.layers.dense(inputs=second_hidden_layer,
                               units=10,
                               activation_fn=tf.sigmoid)
\end{lstlisting}
上面的代码创建一个用sigmoid激活函数(\href{https://www.tensorflow.org/api_docs/python/tf/sigmoid}{tf,sigmoid})和second\_hidden\_layer全连接的output\_layer,更多预定义函数的细节查看\href{https://www.tensorflow.org/api_guides/python/nn#activation_functions}{API docs}
将它们放在一起，下面的代码构造一个完整的神经网络用于Abalone预测器和捕获他的预测:
\begin{lstlisting}[language=Python]
def model_fn(features, labels, mode, params):
  """Model function for Estimator."""

  # Connect the first hidden layer to input layer
  # (features["x"]) with relu activation
  first_hidden_layer = tf.layers.dense(features["x"], 10, activation=tf.nn.relu)

  # Connect the second hidden layer to first hidden layer with relu
  second_hidden_layer = tf.layers.dense(
      first_hidden_layer, 10, activation=tf.nn.relu)

  # Connect the output layer to second hidden layer (no activation fn)
  output_layer = tf.layers.dense(second_hidden_layer, 1)

  # Reshape output layer to 1-dim Tensor to return predictions
  predictions = tf.reshape(output_layer, [-1])
  predictions_dict = {"ages": predictions}
  ...
\end{lstlisting}
这里因为你将用numpy\_input\_fn传递abalone的Datasets,features是一个字典{'X':data\_tensor}，因此features["x"]是输入层，网络包含两个隐藏层，每个层有10个结合ReLU激活函数的节点。输出层没有激活函数\href{https://www.tensorflow.org/api_docs/python/tf/reshape}{tf.reshape}一个一维tensor捕获模型的预测存储在predicions\_dict。
\subsection{为模型定义一个损失}
model\_fn返回的EstimatorSpec必须包含loss:一个代表loss值的Tensor，用来衡量模型在训练和评估运行时预测反映的结果的好坏。\href{https://www.tensorflow.org/api_docs/python/tf/losses}{tf.losses}模块提供方便的函数用多种度量计算损失，包括:
\begin{itemize}
\item absolute_difference(labels,predictions)使用\href{https://en.wikipedia.org/wiki/Deviation_(statistics)#Unsigned_or_absolute_deviation}{absolute-difference formula(正如$L_1$损失)}计算损失
\item log\_loss(labels,predictions)用\href{https://en.wikipedia.org/wiki/Loss_functions_for_classification#Logistic_loss}{logistic loss forumula }计算损失函数(通常使用逻辑回归)
\item mean\_squared\_error(labels,predictions)使用\href{https://en.wikipedia.org/wiki/Mean_squared_error}{mean squared error}计算损失($L_2$损失)
\end{itemize}
下面的例子使用mean\_squared\_error()添加一个定义的loss到abalone的model\_fn
\begin{lstlisting}[language=Python]
def model_fn(features, labels, mode, params):
  """Model function for Estimator."""

  # Connect the first hidden layer to input layer
  # (features["x"]) with relu activation
  first_hidden_layer = tf.layers.dense(features["x"], 10, activation=tf.nn.relu)

  # Connect the second hidden layer to first hidden layer with relu
  second_hidden_layer = tf.layers.dense(
      first_hidden_layer, 10, activation=tf.nn.relu)

  # Connect the output layer to second hidden layer (no activation fn)
  output_layer = tf.layers.dense(second_hidden_layer, 1)

  # Reshape output layer to 1-dim Tensor to return predictions
  predictions = tf.reshape(output_layer, [-1])
  predictions_dict = {"ages": predictions}

  # Calculate loss using mean squared error
  loss = tf.losses.mean_squared_error(labels, predictions)
  ...
\end{lstlisting}
查看\href{https://www.tensorflow.org/api_guides/python/contrib.losses}{API guide}了解更多loss函数的使用和支持的参数。

丰富的估计度量可以被添加到一个eval\_metric\_ops字典。下面的代码定义一个rmse度量，计算模型预测的均方误误差。注意labels tensor转化一个float64类型为predictions匹配的类型的tensor，包含真的值:
\begin{lstlisting}[language=Python]
eval_metric_ops = {
    "rmse": tf.metrics.root_mean_squared_error(
        tf.cast(labels, tf.float64), predictions)
}
\end{lstlisting}
\subsection{定义为model训练操作}
训练操作定义优化算法TensorFlow将你拟合模型到训练数据上是使用。通常当训练的时候，目标是最小化误差。一个简单的方法创建训练操作是实例化一个tf.train.Optimizer子类和调用minimize方法。
下面的代码为abalone的model\_fn定义一个训练操作使用损失值计算\href{https://www.tensorflow.org/extend/estimators#defining_loss}{ Defining Loss for the Model},学习率传递到params中的函数，梯度下降优化器。对于global\_step,方便的函数\href{https://www.tensorflow.org/api_docs/python/tf/train/get_global_step}{tf.train.get\_global\_step}考虑生成一个整数变量。
\begin{lstlisting}[language=Python]
optimizer = tf.train.GradientDescentOptimizer(
    learning_rate=params["learning_rate"])
train_op = optimizer.minimize(
    loss=loss, global_step=tf.train.get_global_step())
\end{lstlisting}
对于优化器的完整列表查看\href{https://www.tensorflow.org/api_guides/python/train#optimizers}{API guid}
\subsection{完整的abalone model\_fn}
这里最终，完整的model\_fn用于abalone年龄预测器。下面的代码配置神经网络，定义损失和训练操作；返回一个EstimatorSpec对象包含mode，predictions\_dict,loss和train\_op：
\begin{lstlisting}[language=Python]
def model_fn(features, labels, mode, params):
  ""Model function for Estimator.""

  # Connect the first hidden layer to input layer
  # (features["x"]) with relu activation
  first_hidden_layer = tf.layers.dense(features["x"], 10, activation=tf.nn.relu)

  # Connect the second hidden layer to first hidden layer with relu
  second_hidden_layer = tf.layers.dense(
      first_hidden_layer, 10, activation=tf.nn.relu)

  # Connect the output layer to second hidden layer (no activation fn)
  output_layer = tf.layers.dense(second_hidden_layer, 1)

  # Reshape output layer to 1-dim Tensor to return predictions
  predictions = tf.reshape(output_layer, [-1])

  # Provide an estimator spec for `ModeKeys.PREDICT`.
  if mode == tf.estimator.ModeKeys.PREDICT:
    return tf.estimator.EstimatorSpec(
        mode=mode,
        predictions={"ages": predictions})

  # Calculate loss using mean squared error
  loss = tf.losses.mean_squared_error(labels, predictions)

  # Calculate root mean squared error as additional eval metric
  eval_metric_ops = {
      "rmse": tf.metrics.root_mean_squared_error(
          tf.cast(labels, tf.float64), predictions)
  }

  optimizer = tf.train.GradientDescentOptimizer(
      learning_rate=params["learning_rate"])
  train_op = optimizer.minimize(
      loss=loss, global_step=tf.train.get_global_step())

  # Provide an estimator spec for `ModeKeys.EVAL` and `ModeKeys.TRAIN` modes.
  return tf.estimator.EstimatorSpec(
      mode=mode,
      loss=loss,
      train_op=train_op,
      eval_metric_ops=eval_metric_ops)"
\end{lstlisting}
\subsection{运行Abalone模型}
你已经为abalone年龄预测器初始化一个Estimator在model\_fn中定义它的行为；所有需要做的是训练，估计，和预测。
字啊面的代码是main()的结尾,拟合神经网络训练数据和估算精度。
\begin{lstlisting}[language=Python]
train_input_fn = tf.estimator.inputs.numpy_input_fn(
    x={"x": np.array(training_set.data)},
    y=np.array(training_set.target),
    num_epochs=None,
    shuffle=True)

# Train
nn.train(input_fn=train_input_fn, steps=5000)

# Score accuracy
test_input_fn = tf.estimator.inputs.numpy_input_fn(
    x={"x": np.array(test_set.data)},
    y=np.array(test_set.target),
    num_epochs=1,
    shuffle=False)

ev = nn.evaluate(input_fn=test_input_fn)
print("Loss: %s" % ev["loss"])
print("Root Mean Squared Error: %s" % ev["rmse"])))
\end{lstlisting}
\begin{quote}
\textbf{注意:}\emph{上面的代码用输入若函数输入features(x)和label(y) Tensor到模型中训练(train\_input\_fn)和估计test\_input\_fn,了解更多输入函数，查看}\href{https://www.tensorflow.org/get_started/input_fn}{Building Input Functions with tf.EstimatorSpec}
\end{quote}
然后运行代码，你应该看到类似下面的输出:
\begin{lstlisting}[language=Python]
...
INFO:tensorflow:loss = 4.86658, step = 4701
INFO:tensorflow:loss = 4.86191, step = 4801
INFO:tensorflow:loss = 4.85788, step = 4901
...
INFO:tensorflow:Saving evaluation summary for 5000 step: loss = 5.581
Loss: 5.581
\end{lstlisting}
损失得分被报告是当运行ABALONE\_TEST数据集来自model\_fn的军方误差。
为ABALONE\_PREDICT数据集预测年龄，添加下面代码到main()：
\begin{lstlisting}[language=Python]
# Print out predictions
predict_input_fn = tf.estimator.inputs.numpy_input_fn(
    x={"x": prediction_set.data},
    num_epochs=1,
    shuffle=False)
predictions = nn.predict(input_fn=predict_input_fn)
for i, p in enumerate(predictions):
  print("Prediction %s: %s" % (i + 1, p["ages"]))))
\end{lstlisting}
这里predict()函数迭代的返回结果在predictions。for训练返回结果，返回代码类似下面:
\begin{lstlisting}[language=Bash]
...
Prediction 1: 4.92229
Prediction 2: 10.3225
Prediction 3: 7.384
Prediction 4: 10.6264
Prediction 5: 11.0862
Prediction 6: 9.39239
Prediction 7: 11.1289
\end{lstlisting}
\subsection{附加资源}
祝贺你，你已经从Estimator成功地构建了一个tf.estimator。更多关于构建Estimator的资料查看下面的API章节:
\begin{itemize}
\item \href{https://www.tensorflow.org/api_guides/python/contrib.layers}{Layers}
\item \href{https://www.tensorflow.org/api_guides/python/contrib.losses}{Losses}
\item \href{https://www.tensorflow.org/api_guides/python/contrib.layers#optimization}{Optimization}
\end{itemize}
