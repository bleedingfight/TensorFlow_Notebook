\documentclass{article}
\usepackage[space]{ctex}
\begin{document}
\section{自编码器}
自编码器是一种能够用来学习对输入数据高效编码的神经网络。若给定一些输入，神经网络首先会使用一系列的变换来将数据映射到低维空间，这部分神经网络就被称为编码器。

然后，网络会使用被编码的低维数据去尝试重建输入，这部分网络称之为解码器。我们可以使用编码器将数据压缩为神经网络可以理解的类型。然而自编码器很少用做这个目的，因为通常存在比它更为有效的手工编写的算法（例如 jpg 压缩）。

此外，自编码器还被经常用来执行降噪任务，它能够学会如何重建原始图像。
有很多与自编码器相关的有趣应用。

其中之一被称为变分自编码器（variational autoencoder）。使用变分自编码器不仅可以压缩数据--还能生成自编码器曾经遇到过的新对象。

使用通用自编码器的时候，我们根本不知道网络所生成的编码具体是什么。虽然我们可以对比不同的编码对象，但是要理解它内部编码的方式几乎是不可能的。这也就意味着我们不能使用编码器来生成新的对象。我们甚至连输入应该是什么样子的都不知道。

而我们用相反的方法使用变分自编码器。我们不会尝试着去关注隐含向量所服从的分布，只需要告诉网络我们想让这个分布转换为什么样子就行了。

通常情况，我们会限制网络来生成具有单位正态分布性质的隐含向量。然后，在尝试生成数据的时候，我们只需要从这种分布中进行采样，然后把样本喂给解码器就行，解码器会返回新的对象，看上去就和我们用来训练网络的对象一样。

下面我们将介绍如何使用 Python 和 TensorFlow 实现这一过程，我们要教会我们的网络来画 MNIST 字符。
\end{document}
