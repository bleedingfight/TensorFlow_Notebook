\chapter{Tensorflow API}
\section{tf.check\_numerics}
check\_numbercs(tensor,message,none):检查一个tensor是NaN或者Inf值。运行的时候如果tensor有任何职不是NaN或者Inf报告一个InvalidArgument错误，否则传递tensor的值。
\begin{itemize}
	\item tensor:一个Tensor，可以使下面的类型:half,float32,float64
	\item message:一个string，错误的前缀
	\item name:操作的名字
	\item[Return]:返回一个和tensor同样类型的Tensor
\end{itemize}
\section{tf.clip\_by\_value}
clip\_by\_value(t,clip\_value\_min,clip\_value\_max,name=None):剪切值为最大值和最小值，给定一个tensor t，操作返回一个和t同样类型，同样大小的值到clip\_value\_min,和clip\_value\_max.任何值小于clip\_value\_min被设置为clip\_value\_min，任何大于clip\_value\_max的值被设置为clip\_value\_max。
参数:
\begin{itemize}
	\item t:一个tensor
	\item clip\_value\_min:一个0维Tensor或者和t相同形状的tensor，取代的最小值
	\item clip\_value\_max:一个0维Tensor或者和t有相同形状的Tensor，取代的大值
	\item name:操作的名字
	\item[Returns]:一个取代后的tensor。
	\item[Raises]:如果剪切的tensor将触发数组的广播操作将安徽比输入更大的返回tensor。
\end{itemize}
\section{tf.app.flags}
\subsection{DEFINE\_boolean}
DEFINE\_boolean(flag\_name,default\_value,docstring):定义一个'boolean'类型的flag。
\begin{itemize}
\item flag\_name:flag的名字，是一个字符串。
\item default\_value:flag应被被看作一个boolean的默认值。
\item docstring:用flag的一个帮助信息。
\end{itemize}
\subsection{DEFINE\_boolean}:定义一个'boolean'类型的flag。
\begin{itemize}
\item flag\_name:flag的名字，是一个字符串。
\item flag\_default\_value:默认的boolean类型的值。
\item docstring:用flag的一个有用的帮助信息。
\end{itemize}
\subsection{DEFINE\_float}:定义一个浮点数类型的flag。
\begin{itemize}
\item flag\_name:作为flag的名字，应该是字符串。
\item default\_value:flag的默认值，应该是浮点数。
\item docstring:用flag的一个有用的帮助信息。
\end{itemize}
\subsection{DEFINE\_integer}:定义一个整数的flag。
\begin{itemize}
\item flag\_name:flag的名字，应该是字符串。
\item default\_value:flag的默认值，应该是一个整数。
\item docstring:用flag的一个有用的帮助信息。
\end{itemize}
\subsection{DEFINE\_string}:定义一个字符串的flag。
\begin{itemize}
\item flag的名字，应该是字符串。
\item default\_value:flag的默认值，应该是字符串。
\item docstring:用flag的一个有用的帮助信息。
\end{itemize}
\subsection{tf.convert\_to\_tensor}
\begin{lstlisting}[language=Python]
convert_to_tensor(
    value,
    dtype=None,
    name=None,
    preferred_dtype=None
)
\end{lstlisting}
转换给定的value为一个Tensor。
这个函数转转Python对象为Tensor对象，接受的Tensor对象有numpy array,Python list,Python标量。例如
\begin{lstlisting}[language=Python]
import numpy as np

def my_func(arg):
  arg = tf.convert_to_tensor(arg, dtype=tf.float32)
  return tf.matmul(arg, arg) + arg

# The following calls are equivalent.
value_1 = my_func(tf.constant([[1.0, 2.0], [3.0, 4.0]]))
value_2 = my_func([[1.0, 2.0], [3.0, 4.0]])
value_3 = my_func(np.array([[1.0, 2.0], [3.0, 4.0]], dtype=np.float32))
\end{lstlisting}
这个函数在组合新的操作时很有用，如上慢的my\_func。所有的标注的Python操作构造体应用这个函数到每个输入的Tensor值，允许这些操作接受numpy数组，Python列表，标量和Tensor对象。
\begin{itemize}
\item value:支持转化为Tensor的数据类型
\item dtype:返回tensor的元素类型。如果确实，类型从value推断
\item name:如果新的Tensor被创建，这个参数决定Tensor的名字
\item preferred\_dtype:返回tensor的元素类型选项，当dtype为None时。在一些情况下，调用器也许没有类型转化为一个tensor，因此preferred\_dtype可能用作软偏好。如果转化为preferred\_dtype不可能，这个参数将不起作用
\item[Returns] 一个基于value的输出
\item[Raises]:TypeError:如果没有转换对象适用与value。RuntimeError：如果转化对象的值不可用
\end{itemize}

\subsection{tf.gather}
\begin{lstlisting}[language=Python]
gather(
    params,
    indices,
    validate_indices=None,
    name=None,
    axis=0
	)
\end{lstlisting}
根据indices从params和axis轴获取slices。
indices必须是任何维度(通常是0维或者一维)的一个整数tensor生成输出tensor的形状params.shape[:axis]+indices.shape+params.shape[axis+1:],这里
\begin{lstlisting}[language=Python]
# Scalar indices (output is rank(params) - 1).
output[a_0, ..., a_n, b_0, ..., b_n] =
params[a_0, ..., a_n, indices, b_0, ..., b_n]
# Vector indices (output is rank(params)).
output[a_0, ..., a_n, i, b_0, ..., b_n] =
params[a_0, ..., a_n, indices[i], b_0, ..., b_n]
# Higher rank indices (output is rank(params) + rank(indices) - 1).
output[a_0, ..., a_n, i, ..., j, b_0, ... b_n] =
params[a_0, ..., a_n, indices[i, ..., j], b_0, ..., b_n]
\end{lstlisting}
\begin{figure}[H]
	\includegraphics[scale=0.5]{Gather.png}
\end{figure}
参数:
\begin{itemize}
	\item params:一个Tensor，从它那里收集值，rank必须是axis+1
	\item indices:一个tensor。必须是int32,int64.索引tensor，必须是在[0,params.shape[axis])
	\item axis:一个Tensor，必须是下面的数据类型:int32,int64.params的轴，从params中获得收集索引，默认是第一维，支持负索引。
	\item name:操作的名字
	\item{返回}:一个tensor，和params有相同的数据类型，通过给定indeces从params收集，形状为[params.shape[:axis]+indices.shape+params.shape[axis+1:]
\end{itemize}
例子:
\begin{lstlisting}[language=Python]
import tensorflow as tf
a = tf.constant([[1,2,3,4],[5,6,7,8],[9,10,11,12],[13,14,15,16]])
b = tf.constant([1,0,2])
g = tf.gather(a,b)
with tf.Session() as sess:
    print(sess.run(g))#获取第一轴[1,0,2]行的数据
\end{lstlisting}
输出:
\begin{lstlisting}[language=Python]
[[ 5  6  7  8]
 [ 1  2  3  4]
 [ 9 10 11 12]]
\end{lstlisting}
\subsection{tf.one\_hot}
\begin{lstlisting}[language=Python]
one_hot(
    indices,
    depth,
    on_value=None,
    off_value=None,
    axis=None,
    dtype=None,
    name=None
)
\end{lstlisting}
返回一个one-hot tensor。
indices位置的值由on\_value表示，其它位置的值由off\_value表示。on\_value和off\_value必须匹配数据类型，如果dtype被提供他们必须和dtype制定的类型相同。

如果on\_value没有没提供，他讲默认为dtype指定的0。off\_value没有提供，他讲默认设置为dtype类型的0。

如果设计日indices rank为N，输出rank将为N+1,新的轴将在axis创建（默认新的轴被添加到末尾）

如果indices是一个标量，输出形状将是一个长度为depth的向量

如果indices是一个长度为features的向量，输出形状将为:
\begin{lstlisting}[language=Python]
features x depth if axis == -1
depth x features if axis == 0
\end{lstlisting}
如果indices是一个矩阵，形状为[batch,features],输出形状将为:
\begin{lstlisting}[language=Python]
batch x features x depth if axis == -1
batch x depth x features if axis == 1
depth x batch x features if axis == 0
\end{lstlisting}
如果dtype没有提供，将尝试假设on\_value和off\_value的类型，如果一个或者两个被传递进去。如果on\_value，off\_value是空或者dtype被提供，dtyoe将默认为tf.float32。
\begin{quote}
如果一个非数值类型输出被妖气，on\_value和off\_value必须提供给one\_hot。
\end{quote}

例如:
\begin{lstlisting}[language=Python]
indices = [0, 1, 2]
depth = 3
tf.one_hot(indices, depth)  # output: [3 x 3]
# [[1., 0., 0.],
#  [0., 1., 0.],
#  [0., 0., 1.]]

indices = [0, 2, -1, 1]
depth = 3
tf.one_hot(indices, depth,
           on_value=5.0, off_value=0.0,
           axis=-1)  # output: [4 x 3]
# [[5.0, 0.0, 0.0],  # one_hot(0)
#  [0.0, 0.0, 5.0],  # one_hot(2)
#  [0.0, 0.0, 0.0],  # one_hot(-1)
#  [0.0, 5.0, 0.0]]  # one_hot(1)

indices = [[0, 2], [1, -1]]
depth = 3
tf.one_hot(indices, depth,
           on_value=1.0, off_value=0.0,
           axis=-1)  # output: [2 x 2 x 3]
# [[[1.0, 0.0, 0.0],   # one_hot(0)
#   [0.0, 0.0, 1.0]],  # one_hot(2)
#  [[0.0, 1.0, 0.0],   # one_hot(1)
#   [0.0, 0.0, 0.0]]]  # one_hot(-1)
\end{lstlisting}
参数:
\begin{itemize}
\item indices:一个索引Tensor
\item depth:一个定义onehot维度的标量
\item on\_value:一个定义填充在输出的标量indices[j]=i(默认为1)
\item off\_value:一个定义填充输出的标量indices[j]!\i(默认为0)
\item axis:一个填充的轴，默认为-1
\item dtype:输出tensor的数据类型
\item[Returns] output:one-hottensor
\item[Raises]:TypeError:如果on\_value或者off\_value和dtype不匹配，或者on\_value和off\_value不匹配
\end{itemize}

\subsection{tf.placeholder}
\begin{lstlisting}[language=Python]
placeholder(
    dtype,
    shape=None,
    name=None
)
\end{lstlisting}
为placeholder输入需要被插入的tensor。
如果这个tensor被计算将产生错误。它的值必须通过feed\_dict选项在Session.run(),Tensor.eval()或者是Operation.eval()输入。
\begin{lstlisting}[language=Python]
x = tf.placeholder(tf.float32, shape=(1024, 1024))
y = tf.matmul(x, x)
with tf.Session() as sess:
    print(sess.run(y))  # ERROR: will fail because x was not fed.
    rand_array = np.random.rand(1024, 1024)
    print(sess.run(y, feed_dict={x: rand_array}))  # Will succeed.
\end{lstlisting}
参数:
\begin{itemize}
\item dtype:被输入的tensor元素的数据类型。
\item shape:被fed的tensor的形状，如果形状没有被指定，你可以输入任何形状的tensor。
\item:操作的名字
\item{Return} 一个可能被用作输入数据处理的Tensor，值不能被直接计算。
\end{itemize}
\subsection{tf.py\_func}
py\_func(func, inp, Tout, stateful=True, name=None)打包一个python函数将它用作一个TensorFlow操作，给一个Python函数'func',接受numpy数组作为它的输入返回numpy数组作为输出，转化函数作为一个TensorFlow图上的操作。下面的代码段构造一个简单的TensorFlow图利用`np.sinh()` Numpy函数作为一个图上的操作:
\begin{lstlisting}[language=Python]
 def my_func(x):
      # x will be a numpy array with the contents of the placeholder below return np.sinh(x)
    inp = tf.placeholder(tf.float32)
    y = tf.py_func(my_func, [inp], tf.float32)
\end{lstlisting}
\begin{quote}
	\emph{tf.py\_func()操作有如下已知的限制:}
	\begin{itemize}
			\item 在GraphDef中函数将不被序列化，因此，如果你需要序列化你的模型和从不同的模型中恢复它，你不能用这个函数
			\item 这个操作必须运行在和Python程序相同的地址空间，如果你用分布式的TensorFlow，你必须在痛痛的进程运行tf.train.Saver作为程序调用。
			\item tf.py\_func()和你必须添加创建的操作到服务器的设备上
	\end{itemize}
参数:
\begin{itemize}
		\item 一个Python函数接受一个和`inp`对应的tf.Tensor对象元素类型匹配的NumPy ndarray对象列表,返回一个`adarray`对象（或者一个ndarray），它和`Tout`中对应的值有相同的类型。
		\item inp:一个`Tensor`对象列表
		\item Tout:一个tensorflow数据类型的列表或者元祖，或者如果仅有一个值的话为一个单个的tensorflow数据
		\item statefull:bool行，如果为True，函数井盖被认为stateful的，如果是stateless的，当给定相同的输入将返回相同的输出没有可见的副作用。优化像常见的子表达式减少仅仅在stateless上操作
		\item name：操作的名字
		\item[返回] 一个Tensor列表或者一个`func`计算的Tensor。
\end{itemize}
\end{quote}
\subsection{tf.read\_file}
读取输出输入文件filename的整个内容
参数:
\begin{itemize}
		\item filename:一个`string`类型的`Tensor`
		\item name:操作的名字
		\item[返回值] 一个`string`类型的`Tensor`
\end{itemize}
\subsection{tf.squeeze}
tf.squeeze(input,axis=None,name=None,squeeze\_dims=None)
说明:从指定的Tensor中移除1维度。
\begin{itemize}
\item input:tensor,输入Tensor。
\item axis:列表，指定需要移除的位置的列表，默认为空列表[],索引从0开始squeeze不为1的索引会报错。
\item name:操作的名字
\item squeeze\_dims:否决当前轴的参数。
\item 返回一个Tensor，形状和input相同，包含和input相同的数据，但是不包含有1的元素。
\item 异常：squeeze\_dims和axis同时指定时会有ValueError。
\end{itemize}
\# 't' is a tensor of shape [1, 2, 1, 3, 1, 1]\newline
shape(squeeze(t)) ==> [2, 3]\newline
\# 't' is a tensor of shape [1, 2, 1, 3, 1, 1]\newline
shape(squeeze(t, [2, 4])) ==> [1, 2, 3, 1]\newline
\subsection{tf.metrics}
accuracy(labels,predictions,weights=none,metrics\_collections,updates\_collections=none,name=none)
\begin{itemize}
	\item labels:tensor，和predictions的形状相同，代表真实值。
	\item predictions:tensor，代表预测值。
	\item weights:tensor，rank可以为0或者labels的rank，必须能和label广播（所有的维度必须是1,或者和labels维度相同）
	\item metrics\_collection:accuracy应该被增加的一个collectiobn列表选项。
	\item update\_collections:update\_op应该添加的选项列表。
	\item name:variable\_scope名字选项。
	\item accuracy:返回值tensor，代表精度，总共预测对的和总数的商。
	\item update\_op:返回值适当增加total和count变量和accuracy匹配。
	\item valueerror:异常如果predictions和labels有不同的形状，或者weight不是none它的形状不合prediction匹配，或者metrics\_collections会哦这updates\_collections不是一个list或者tuple。
\end{itemize}
\subsection{tf.split}
split(value,num\_or\_size\_splits,axis=0,num=None,name='split')：分割一个Tensor,如果num\_or\_size\_split是一个整数类型，num\_split然后沿着axis分割value为num\_split更小的tensors。要求num\_split均匀分割为value.shape[axis]。如果num\_or\_size\_splits不是一个整数类型，它被将定位一个Tensorsize\_splits,然后分割值为len(size\_splits)段，第i个形状有相同的大小作为value除了沿着维度axis，这里的size是size\_splits[i]。
\begin{lstlisting}[language=Python]
#value是一个形状为[5,30]的tensor
#分割沿着1轴分割'value'为3个tensor，形状为【4,15,11】
split0,split1,split2 = tf.split(value,[4,15,11],1)
tf.shape(split0) ==>[5,4]
tf.shape(split1) ==>[5,15]
tf.shape(split2) ==>[5,11]
#沿着1轴分割‘value’为三个tensor
split0,split1,split2 = tf.split(value,num_or_size_split=3,axis=1)
tf.shape(split0) ==>[5,10]
\end{lstlisting}
参数:
\begin{itemize}
	\item value:要分割的Tensor
	\item num\_or\_size\_splits:是一个0维整数Tensor，表示沿着split\_dim或者包含每个分割长度的1维整数tensor分割多少份。如果是标量将被均匀分割为value.shape[axis]。否者沿着分割维度求和必须和value匹配。
	\item axis:0维 int32 tensor，沿着分割的维度，必须在[-rank(value),rank(value)],默认为0。
	\item num:选项，不能推断出时用于指定size\_split输出数
	\item name:操作的名字
	\item [Returns]:如果num\_or\_size\_split是一个标量返回num\_or\_size\_split是一个一维Tensor返回value分割的num\_or\_size\_splits.get\_shape[0] Tensor对象
	\item [Raises]:如果num不被指定也不能被推断出。将产生ValueError
\end{itemize}
\subsection{tf.stack}
stack(values,axis=0,name='stack')：stack一个n维tensor为n+1维tensor。
给定一个长度为N的形状为(A,B,C)的tensor，如果axis==0输出tensor的形状为(N,A,B,C),如果axis==1,输出tensor的形状为(A,N,B,C)
\# 'x' is [1,4]\newline
\# 'y' is [3,6]\newline
\# 'z' is [3,6]\newline
stack([x,y,z])==>[[1,4],[2,5],[3,6]]\newline
stack(x,y,z,axis=1)==>[[1,2,3],[4,5,6]]\newline
tf.stack([x,y,z]) = np.asarray([x,y,z])\newline
输出参数:
\begin{itemize}
	\item 一个Tensor列表。
	\item 整数，默认为0,支持负坐标。
	\item 操作的名字。
	\item[\S] 一个stack的Tensor。
	\item[\S] ValueError:如果axis超过[-(R+1),R+1)
\end{itemize}
\textsl{Example}
\begin{lstlisting}[language=Python]
import tensorflow as tf
x = tf.constant([1,4])
y = tf.constant([2,5])
z = tf.constant([3,6])
r1 = tf.stack([x,y,z])
r2 = tf.stack([x,y,z],axis=1)
with tf.Session() as sess:
    print(sess.run(r1).shape)
    print(sess.run(r2).shape)
\end{lstlisting}
\subsection{tf.reshape}
tf.reshape(tensor,shape,name=None)
\begin{itemize}
	\item Tensor:一个Tensor。
	\item shape:一个列表,数值类型为int32或者时int64
	\item name:操作的名字。
	\item[S] 指定形状的Tensor。
\end{itemize}
\begin{lstlisting}[language=Python]
import tensorflow as tf
a = tf.linspace(0.,9.,10)
b = tf.reshape(a,[2,5])
with tf.Session() as sess:
    a = sess.run(a)
    b = sess.run(b)
print(a.shape)
print(b.shape)
\end{lstlisting}
\subsection{tf.random\_crop}
\begin{lstlisting}[language=Python]
random_crop(
    value,
    size,
    seed=None,
    name=None
)
\end{lstlisting}
从value tensor随机剪裁一块指定size的tensor，要求value。shape大于参数size的值。如果一维不剪切需要传递完整的size，例如RGB图像可以用size = [crop\_height,crop\_width,3]剪切。

输入参数:
\begin{itemize}
\item value:需要被剪切的tensor
\item size:和value有相同rank的一维tensor。
\item seed:Python整数，用于创建一个随机种子。
\item name:操作的名字。
\item[Retuen] 一个剪切的和value有相同的rank，形状为size的tensor。
\end{itemize}
\subsection{tf.random\_gamma}
\begin{lstlisting}[language=Python]
random_gamma(
    shape,
    alpha,
    beta=None,
    dtype=tf.float32,
    seed=None,
    name=None
)
\end{lstlisting}
从指定\href{https://zh.wikipedia.org/wiki/伽玛分布}{Gamma分布}中获得shape样本，alpha是形状参数，beta是反向放大参数。

输入参数:
\begin{itemize}
\item shape:一个一维整数Tensor或者Python数组，指定alpha，beta参数的输出采样数据。
\item alpha:一个tensor或者python值或者N维dtype数据类型。alpha提供形状参数，必须和beta广播。
\item beta:一个tensor或python值或者dtype类型的n维数组。默认为1.beta提供gamma分布的反向放大参数。必须和alpha广播。
\item dtype:alpha,beta,output的输出:float16,float32或者float64。
\item seed:一个Python整数，用于创建随机种子。
\item name:操作的选项。
\item[Returns]:
samples:数据类型为dtype的一个形状为tf.concat(shape,tf.shape(alpha+beta))的tensor。
\end{itemize}
例子:
\begin{lstlisting}[language=Python]
samples = tf.random_gamma([10],[0.5,1.5])#形状为10,alpha为0.5，1.5,采样输出形状为[10,2]
samples = tf.random_gamma([7, 5], [0.5, 1.5]) # 采样输出形状为[7, 5, 2], where each slice [:, :, 0] and [:, :, 1] # 代表从两个分布采样的$7\items5$。
samples = tf.random_gamma([30], [[1.],[3.],[5.]], beta=[[3., 4.]]) #采样输出形状[30, 3, 2], 每$2\times2$（广播运算）30个采样点
\end{lstlisting}
\subsection{tf.random\_normal}
\begin{lstlisting}[language=Python]
random_normal(
    shape,
    mean=0.0,
    stddev=1.0,
    dtype=tf.float32,
    seed=None,
    name=None
)
\end{lstlisting}
输出正态分布随机值。

输入参数:
\begin{itemize}
\item shape:一个一维整数tensor或者Python数组。表示输出tensor的形状。
\item mean：一个0维tensor和dtype的Python值，正态分布的均值。
\item stddev:一个0维tensor和dtype的Python值，正态分布的标准差。
\item stype:输出数据类型。
\item seed:一个整数，用于创建一个随机数种子。
\item name:操作的名字。
\item[Returns] 制订形状的正态分布值。
\end{itemize}
\subsection{\textbf{tf.random\_normal\_initializer}}
继承于\href{https://www.tensorflow.org/api_docs/python/tf/contrib/keras/initializers/Initializer}{Initializer}
别名:
\begin{itemize}
\item Class tf.contrib.keras.initializers.RandomNormal
\item Class tf.random\_normal\_initializer
\end{itemize}
输入参数:
\begin{itemize}
\item mean:一个python标量或者标量tensor。生成随机值的均值。
\item stddev:一个python标量或者标量tensor。标生成随机值的标准差。
\item seed:python整数，用于创建随机种子。
\item dtypes:数据类型，仅仅支持浮点数类型。
\end{itemize}
方法:
\begin{itemize}
\item \_\_init\_\_
\begin{lstlisting}[language=Python]
__init__(
    mean=0.0,
    stddev=1.0,
    seed=None,
    dtype=tf.float32
)
\end{lstlisting}
\item \_\_call\_\_
\begin{lstlisting}[language=Python]
__call__(
    shape,
    dtype=None,
    partition_info=None
)
\end{lstlisting}
\item from\_config:从配置字典实例化initilizer。
\begin{lstlisting}[language=Python]
from_config(
    cls,
    config
)
\end{lstlisting}
例如:
\begin{lstlisting}[language=Python]
initializer = RandomUniform(-1, 1)
config = initializer.get_config()
initializer = RandomUniform.from_config(config)
\end{lstlisting}
\item get\_config()
\end{itemize}
\subsection{tf.random\_possion}
\begin{lstlisting}[language=Python]
random_poisson(
    lam,
    shape,
    dtype=tf.float32,
    seed=None,
    name=None
)
\end{lstlisting}
从Poisson分布中获取制定形状的样本，lam是描述分布的参数。

输入参数:
\begin{itemize}
\item lam:一个Tensor或者Python值或者dtype指定的N维数组。lam是Poisson分布的参数。
\item shape:yuige一维整数tensor或者python数组，输出每个rate指定的参数的形状。
\item dtype:lam和输出的数据类型:float16,float32,float64.
\item seed:Python整数，用于创建一个分布的随机种子。
\item name:操作的名字。
\item[Returns]:形状为tf.concat(shape,tf,shape(lam))的tensor（值的数据类型如dtype指定）。
\end{itemize}
例子:
\begin{lstlisting}[language=Python]
samples = tf.random_poisson([0.5, 1.5], [10]) # 采样输出形状为[10, 2],切片输出 [:, 0] and [:, 1] 代表不同分布的数据

samples = tf.random_poisson([12.2, 3.3], [7, 5]) # 采样输出形状[7, 5, 2], chide切片[:, :, 0]和[:, :, 1]代表 $7\times5$从两个分布的采样输出。
\end{lstlisting}
\subsection{random\_shuffle}
\begin{lstlisting}[language=Python]
random_shuffle(
    value,
    seed=None,
    name=None
)
\end{lstlisting}
沿着tensor的一维随机打乱数据。像value[j]映射一个tensor到一个数出output[i]。例如
\begin{lstlisting}[language=Python]
[[1, 2],       [[5, 6],
 [3, 4],  ==>   [1, 2],
 [5, 6]]        [3, 4]]
\end{lstlisting}
输入参数:
\begin{itemize}
\item value:一个应该被打乱的值。
\item seed:一个python正数用于创建随机数种子。
\item name:操作的名字。
\item[Returns] 一个指定类型的值和形状，沿着某一维读被打乱的tensor。
\end{itemize}
\subsection{tf.random\_uniform}
\begin{lstlisting}[language=Python]
random_uniform(
    shape,
    minval=0,
    maxval=None,
    dtype=tf.float32,
    seed=None,
    name=None
)
\end{lstlisting}
输出均匀分布的随机值，生成的值的范围在[minival,maxval),下界minval包含在范围内，上界不再。对于浮点数默认范围是[0,1)。至少maxval必须被明确指定。在整数情况下，会有一些轻微的偏移，除非maxval-minval是2的次幂。偏移是maxval-minval
比较小的值相对于输出范围(2**32,2**64)很小。

输入参数:
\begin{itemize}
\item shape:一维整数tensor或者Python数组，和数出tensor的形状相同。
\item minval:0维tensor或者dtype指定的python值，生成随机数的下界，默认为0,。
\item maxval:0维tensor或者dtype指定的python值。生成随机数的上界，dtype是浮点数时，默认为1。
\item dtype:输出的类型:'float16,float32,float64,int32,int64'。
\item seed:一个Python整数。用于创建分布的随机数种子。
\item 操作的名字。
\item [Return] 返回指定形状的均匀分布值。
\item [Raise] ValueError:如果dtype是整数并且maxval没有被指定。
\end{itemize}
\subsection{\textbf{tf.random\_uniform\_initializer}}
一个继承自Initilizer的类。

别名:
\begin{itemize}
\item tf.contrib.keras.initializers.RandomUniform
\item tf.random\_uniform\_initializer
\end{itemize}
生成均匀分布tensor的initializer。

输入参数:
\begin{itemize}
\item minval:0维tensor或者dtype指定的python值，生成随机数的下界，默认为0,。
\item maxval:0维tensor或者dtype指定的python值。生成随机数的上界，dtype是浮点数时，默认为1。
\item seed:一个Python整数。用于创建分布的随机数种子。
\item dtype:输出的类型:'float16,float32,float64,int32,int64'。
\end{itemize}
方法:
\begin{itemize}
\item \begin{lstlisting}[language=Python]__init__(
    minval=0,
    maxval=None,
    seed=None,
    dtype=tf.float32
)\end{lstlisting}
\item \_\_call\_\_
\begin{lstlisting}[language=Python]
__call__(
    shape,
    dtype=None,
    partition_info=None
)
\end{lstlisting}
\item from\_config
\begin{lstlisting}[language=Python]
from_config

from_config(
    cls,
    config
)
\end{lstlisting}
\item get\_config
\end{itemize}
\subsection{tf.transpose}
tf.transpose(a,perm=none,name='transpose'):根据perm改变a的维度，返回一个tensor，它的维度i和perm[i]对应，如果perm没有给定，它被设置为(n-1,\ldots,0),z这是n是输入tensor的rank，输入是2维tensor是执行常规的转置操作:
\begin{lstlisting}[language=Python]
# 'x' is[[1 2 3],[4 5 6]]
tf.transpose(x)==>[[1 4]
		   [2 5]
		   [3 6]]
#等价于
tf,transpose(x,[1,0])==>[[1 4]
			 [2 5]
			 [3 6]]
# perm对于n为tensor很有用，n>2
# x  [[[1,2,3]
#       [4,5,6]]
#       [[7 8 9]
#       [10,11,12]]]
tf.transpose(x,perm=[0,2,1])==>[[[1 4]
				[2 5]
				[3,6]]

				[[7 10]
				[8 11]
				[9 12]]]
\end{lstlisting}
参数:
\begin{itemize}
	\item a:一个Tensor
	\item perm:一个a的维度的乱序
	\item name:操作的名字
	\item[Return] 一个转置后的Tensor
\end{itemize}
\subsection{tf.one\_hot}
\begin{lstlisting}[language=Python]
ne_hot(
    indices,
    depth,
    on_value=None,
    off_value=None,
    axis=None,
    dtype=None,
    name=None
)
\end{lstlisting}
返回一个One-hot tensor。
indices表示的下表的值为on\_value,所有其它值为off\_value。

如果on\_value不提供，默认为dtype下的1。off\_value不提供，默认值为0,如果输入Incices rank是N，输出rank将是N+1。新的axis将在axis创建。，如果indices是一个标量，输出形状将是一个depth长度的向量，如果indices是亿个长度为features向量输出形状将为:
\begin{lstlisting}[language=Python]
feature x depth ifn axis == -1
depth x features if axis == 0
\end{lstlisting}
如果indices是一个矩阵，形状为[batch,features],输出形状将为:
\begin{lstlisting}[language=Python]
 batch x features x depth if axis == -1
  batch x depth x features if axis == 1
  depth x batch x features if axis == 0
\end{lstlisting}
如果dtype没有被提供，它将假设on\_value或off\_value的数据类型，如果一个或者更多的值被传递，，如果没有on\_value,off\_value,或者dtype被提供，dtype将默认tf.float32。
例子:

假设：
\begin{lstlisting}[language=Python]
indices = [0, 2, -1, 1]
  depth = 3
  on_value = 5.0
  off_value = 0.0
  axis = -1
\end{lstlisting}
输出形状为[$4\times3$]
输出:
\begin{lstlisting}[language=Python]
output =
  [5.0 0.0 0.0]  // one_hot(0)
  [0.0 0.0 5.0]  // one_hot(2)
  [0.0 0.0 0.0]  // one_hot(-1)
  [0.0 5.0 0.0]  // one_hot(1)
\end{lstlisting}
假设:
\begin{lstlisting}[language=Python]
 indices = [[0, 2], [1, -1]]
  depth = 3
  on_value = 1.0
  off_value = 0.0
  axis = -1

\end{lstlisting}
输出
\begin{lstlisting}[language=Python]
output =
  [
    [1.0, 0.0, 0.0]  // one_hot(0)
    [0.0, 0.0, 1.0]  // one_hot(2)
  ][
    [0.0, 1.0, 0.0]  // one_hot(1)
    [0.0, 0.0, 0.0]  // one_hot(-1)
  ]
\end{lstlisting}
用默认on\_value和off\_value:
\begin{lstlisting}[language=Python]
indices = [0, 1, 2]
  depth = 3
\end{lstlisting}
输出
\begin{lstlisting}[language=Python]
  output =
  [[1., 0., 0.],
   [0., 1., 0.],
   [0., 0., 1.]]
\end{lstlisting}
参数:
\begin{itemize}
\item indices:一个索引的Tensor。
\item depth:一个定义one hot维度的深度的标量。
\item on\_vlaue:制定Indices[j]=i(填入i)，默认为1。
\item off\_value:一个标量当Indices[j]!=i(默认为0)。
\item axis:填入的轴，默认为-1。
\item dtype:输出tensor的数据类型。
\item [Returns]:one-hot tensor。
\item [Raise]
\begin{itemize}
\item TypeError:如果dtype和on\_value,off\_value数据类型不一样。
\item TypeError:如果on\_value和off\_value不合另一个匹配。
\end{itemize}
\end{itemize}
\subsection{tf.tile}
\begin{lstlisting}[language=Python]
tile(
    input,
    multiples,
    name=None
)
\end{lstlisting}
用给定的tensor铺出一个tensor，通过复制input tensor multiples次。输出tensor的第i维有input.dims(i)*multiples[i]个元素，输入值被沿着i维复制multipiles[i]次。例如[a b,c,d]乘上[2]生成[a b c d a b c d]
参数:
\begin{itemize}
\item input:一个Tensor，一维或者更高维度
\item multiples:一个Tensor。必须是下面的类型:int32,int64。一维长度必须和输出维度相同。
\item name:操作的名字(可选)
\item[Returns]:一个Tensor，和input有相同的数据类型
\end{itemize}

\subsection{tf.unstack}
\begin{lstlisting}[language=Python]
unstack(
    value,
    num=None,
    axis=0,
    name='unstack'
)
\end{lstlisting}
unstack rank-R为rank-(R-1)的tensor。

通过沿着axis维度从value剪切num个tensor。如果num不被指定(默认)它从value的形状推算。如果value.shape[axis]不知道，ValueError异常。
例如一个tensor的形状为(A,B<C<D);
如果 axis == 0输出第i个tensor是切片value[i,:,:,:]，output的每个tensor形状为(B,C,D).（注意沿着维度unstack）
如果axis == 1输出的第i个tensor是切片的值[:,i,:,:]和每个output的每个输出将有形状(A,C,D)。
tf.ustack(x,n)=list(x)

参数:
\begin{itemize}
\item value:rank R>0的Tensor能被unstack。
\item num 一个整数。axis的长度，如果为None将自动推断。
\item axis:一个整数。ustack沿着的轴。默认是第一维，支持负的索引。
\item name:操作的名字。
\item[Returns] 从value unstack的Tensor列表。
\item[Raises]:
\begin{itemize}
\item ValueError:如果num没有被指定且不能推断出。
\item ValueError:如果axis超过[-R,R)。
\end{itemize}
\end{itemize}
\subsection{tf.contrib.rnn}
\subsubsection{AttentionCellWrapper}
继承自RNNCell，是一个基本的attention cell包装器。\newline
\begin{tabular}{|c|c|}
	graph&\_\_init\_\_\\
	losses&\_\_call\_\_\\
	non\_trainable\_variables&\_\_deepcopy\_\_\\
	non\_trainable\_weights&add\_loss\\
	output\_size&add\_update\\
	scope\_size&add\_variable\\
	state\_size&apply\\
	trainable\_variable&build\\
	trainable\_weights&call\\
	updates&get\_losses\_for\\
	vaiables&get\_updates\_for\\
	weights&zero\_state\\
\end{tabular}
